{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ids of the gutenberg corpus:\n",
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
      "\n",
      "File ids of the webtext corpus:\n",
      "['firefox.txt', 'grail.txt', 'overheard.txt', 'pirates.txt', 'singles.txt', 'wine.txt']\n",
      "\n",
      "Text1 id is:  austen-emma.txt\n",
      "Text2 id is:  grail.txt\n",
      "\n",
      "Text1_words :  ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']\n",
      "Text2_words :  ['SCENE', '1', ':', '[', 'wind', ']', '[', 'clop', 'clop', 'clop']\n",
      "\n",
      "Index of the token \"flower\" in text1_words:  110552\n",
      "Token number 110552 in text1_words:  flower\n",
      "\n",
      "Text1_raw, first 100 characters:\n",
      " [Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a\n",
      "\n",
      "Text1_string, made with join() method has extra whitespaces:\n",
      " [ Emma by Jane Austen 1816 ] VOLUME I CHAPTER I Emma Woodhouse , handsome , clever , and rich , with\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using built NLTK built-in text corpus and its methods.\n",
    "# You can load and use your own external texts. See the part \"Load your own text\" \n",
    "# More info at https://www.nltk.org/book/ch02.html\n",
    "\n",
    "import nltk\n",
    "# Uncomment the download dialouge in case you don't have the corpora\n",
    "#nltk.download()\n",
    "\n",
    "#from nltk.book import * #This says \"from NLTK's book module, load all items.\"\n",
    "# It is just a small module for educational purpose in chapter 1 of the NLTK tutorial\n",
    "# In this code we teplicate the classes that has been used in nltk.book module\n",
    "from nltk.corpus import gutenberg, webtext\n",
    "from __future__ import print_function\n",
    "\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import bigrams\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "#Loading\n",
    "###########################################\n",
    "\n",
    "gutenberg_fileids = gutenberg.fileids()\n",
    "webtext_fileids = webtext.fileids()\n",
    "\n",
    "print('File ids of the gutenberg corpus:\\n{}\\n'.format(gutenberg.fileids()))\n",
    "print('File ids of the webtext corpus:\\n{}\\n'.format(webtext.fileids()))\n",
    "\n",
    "#Selecting two sample text\n",
    "text1_id = gutenberg.fileids()[0]\n",
    "text2_id= webtext.fileids()[1]\n",
    "print('Text1 id is: ',text1_id)\n",
    "print('Text2 id is: ',text2_id)\n",
    "text1_words=gutenberg.words(text1_id)\n",
    "text2_words=webtext.words(text2_id)\n",
    "print()\n",
    "\n",
    "#Printing a part of sample texts\n",
    "print('Text1_words : ',text1_words[0:10])\n",
    "print('Text2_words : ',text2_words[0:10])\n",
    "print()\n",
    "\n",
    "#Accesing\n",
    "print('Index of the token \"flower\" in text1_words: ', text1_words.index('flower'))\n",
    "print('Token number 110552 in text1_words: ', text1_words[110552])\n",
    "print()\n",
    "\n",
    "#Using nltk raw string\n",
    "#Notice the difference between raw text and rejoined text1_words. The later one has extra whitespaces and no line break.\n",
    "text1_raw=gutenberg.raw(text1_id)\n",
    "text1_string=\" \".join(text1_words)\n",
    "print('Text1_raw, first 100 characters:\\n',text1_raw[0:100])\n",
    "print()\n",
    "print('Text1_string, made with join() method has extra whitespaces:\\n',text1_string[0:100])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters number of text1_raw austen-emma.txt: 887071\n",
      "Words number of text1_raw austen-emma.txt: 192427 \n",
      "Sentences number of text1_raw austen-emma.txt: 7752 \n",
      "\n",
      "Characters number of text1_string austen-emma.txt: 915041\n",
      "\n",
      "Unique tokens number in text1_words is:  7811\n",
      "Occurence number of the word \"good\" in text1_words is:  340\n",
      "\n",
      "Type of the variable \"text1_raw\" : <class 'str'>\n",
      "Tokens number of text1_raw austen-emma.txt using split(): 158167 \n",
      "Tokens number of text1_raw austen-emma.txt using nltk.word_tokenize: 191673 \n",
      "\n",
      "Type of the variable \"fd\" : <class 'nltk.probability.FreqDist'>\n",
      "Frequency of the word \"good\" in text1 is: 340\n"
     ]
    }
   ],
   "source": [
    "#Tokenizing and Counting\n",
    "###########################################\n",
    "\n",
    "#Note: For counting the characters you must use e.g. raw text. If your text string is made by the join() method \n",
    "#      from a list, your text will have extra whitespace. e.g.   I asked her: \"how are you?\"\n",
    "#                                                         vs     I asked her : \" how are you ? \"\n",
    "######################\n",
    "######################\n",
    "\n",
    "#Text lengths\n",
    "characters_number = len(gutenberg.raw(text1_id))\n",
    "words_number = len(gutenberg.words(text1_id))\n",
    "sentences_number = len(gutenberg.sents(text1_id))\n",
    "\n",
    "print('Characters number of text1_raw {}: {}'.format(text1_id, characters_number))\n",
    "print('Words number of text1_raw {}: {} '.format(text1_id, words_number))\n",
    "print('Sentences number of text1_raw {}: {} '.format(text1_id, sentences_number))\n",
    "print()\n",
    "print('Characters number of text1_string {}: {}'.format(text1_id, len(text1_string)))\n",
    "print()\n",
    "\n",
    "\n",
    "#notice that set return a list of unique tokens\n",
    "print('Unique tokens number in text1_words is: ',len(set(text1_words))) #notice that set return a list of unique tokens\n",
    "print('Occurence number of the word \"good\" in text1_words is: ',text1_words.count('good'))\n",
    "print()\n",
    "print('Type of the variable \"text1_raw\" :', type(text1_raw))\n",
    "#Tokenizing with python split() method\n",
    "print('Tokens number of text1_raw {} using split(): {} '.format(text1_id, len(text1_raw.split())))\n",
    "#Tokenizing with python nltk.word_tokenize\n",
    "print('Tokens number of text1_raw {} using nltk.word_tokenize: {} '.format(text1_id, len(word_tokenize(text1_raw))))\n",
    "print()\n",
    "\n",
    "fd = nltk.FreqDist(text1_words) # creates a new data object that contains information about word frequency\n",
    "print('Type of the variable \"fd\" :', type(fd))\n",
    "print('Frequency of the word \"good\" in text1 is:', fd['good'])\n",
    "#fd.keys(), fd.values(), fd.items()\n",
    "#print(gutenberg.raw(text1_id)[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the variable \"text1_words\" : <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "Type of the variable \"text1_list\" : <class 'list'>\n",
      "\n",
      "7 concordance of the word \"precisely\":\n",
      "Displaying 7 of 7 matches:\n",
      "osity . The yeomanry are precisely the order of people with\n",
      "old you yesterday he was precisely the height of Mr. Perry \n",
      "mbled there , consisting precisely of those whose society w\n",
      "stay at home . '' It was precisely what Emma would have wis\n",
      "s time with us . This is precisely what I wanted . Well , p\n",
      "rank the whole spring -- precisely the season of the year w\n",
      "an , and his manners are precisely what I like and approve \n",
      "\n",
      "\"precisely\" similar contexs:\n",
      "just to in at exactly perhaps by for more now however so that not all\n",
      "on this over gone always\n",
      "\n",
      "\"head\" and \"hart\" common contexs (tokens in left and rightside):\n",
      "his_at his_and her_was my_and my_i own_and\n"
     ]
    }
   ],
   "source": [
    "#Text objects / Concordance, similarity, common_contexts\n",
    "###########################################\n",
    "\n",
    "#Creating text list\n",
    "print('Type of the variable \"text1_words\" :', type(text1_words))\n",
    "text1_list=word_tokenize(text1_raw)\n",
    "print('Type of the variable \"text1_list\" :', type(text1_list))\n",
    "print()\n",
    "\n",
    "#Crating an instance of the NLTK text object\n",
    "text_object=Text(text1_list)\n",
    "\n",
    "#Concordance\n",
    "###########################################\n",
    "\n",
    "#7 concordances of the word \"precisely\":\n",
    "print('7 concordance of the word \"precisely\":')\n",
    "text_object.concordance(word='precisely',width=60, lines=7)\n",
    "\n",
    "#Similarity - find words that are in common context\n",
    "###########################################\n",
    "print()\n",
    "print('\"precisely\" similar contexs:')\n",
    "text_object.similar('precisely')\n",
    "\n",
    "#Common context\n",
    "###########################################\n",
    "print()\n",
    "print('\"head\" and \"hart\" common contexs (tokens in left and rightside):')\n",
    "text_object.common_contexts(['head','heart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
