{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ids of the gutenberg corpus:\n",
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
      "\n",
      "File ids of the webtext corpus:\n",
      "['firefox.txt', 'grail.txt', 'overheard.txt', 'pirates.txt', 'singles.txt', 'wine.txt']\n",
      "\n",
      "Text1 id is:  austen-emma.txt\n",
      "Text2 id is:  grail.txt\n",
      "\n",
      "Text1 austen-emma.txt lenght: 192427 tokens\n",
      "Text2 grail.txt lenght: 16967 tokens\n",
      "\n",
      "Text1_list :  ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']\n",
      "Text2_list :  ['SCENE', '1', ':', '[', 'wind', ']', '[', 'clop', 'clop', 'clop']\n",
      "\n",
      "Index of the token \"flower\":  110552\n",
      "Token number 110552:  flower\n",
      "\n",
      "First 100 characters of joined text1_string: \n",
      " [ Emma by Jane Austen 1816 ] VOLUME I CHAPTER I Emma Woodhouse , handsome , clever , and rich , with\n",
      "First 100 characters of joined text2_string: \n",
      " SCENE 1 : [ wind ] [ clop clop clop ] KING ARTHUR : Whoa there ! [ clop clop clop ] SOLDIER # 1 : Ha\n",
      "\n",
      "Text1_string_resplit :  ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']\n",
      "Text2_string_resplit :  ['SCENE', '1', ':', '[', 'wind', ']', '[', 'clop', 'clop', 'clop']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# An example of commonly used NLTK functions.\n",
    "# More info at http://www.nltk.org/py-modindex.html\n",
    "\n",
    "import nltk\n",
    "# Uncomment the download dialouge in case you don't have the corpora\n",
    "#nltk.download()\n",
    "\n",
    "from nltk.book import * #This says \"from NLTK's book module, load all items.\"\n",
    "# It is just a small module for educational purpose in chapter 1 of the NLTK tutorial\n",
    "# In this code we teplicate the classes that has been used in nltk.book module\n",
    "from nltk.corpus import gutenberg, webtext\n",
    "from __future__ import print_function\n",
    "\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import bigrams\n",
    "\n",
    "\n",
    "#Loading\n",
    "###########################################\n",
    "gutenberg_fileids = gutenberg.fileids()\n",
    "webtext_fileids = webtext.fileids()\n",
    "\n",
    "print('File ids of the gutenberg corpus:\\n{}\\n'.format(gutenberg.fileids()))\n",
    "print('File ids of the webtext corpus:\\n{}\\n'.format(webtext.fileids()))\n",
    "\n",
    "#Selecting two sample text\n",
    "text1_id = gutenberg.fileids()[0]\n",
    "text2_id= webtext.fileids()[1]\n",
    "print('Text1 id is: ',text1_id)\n",
    "print('Text2 id is: ',text2_id)\n",
    "text1_list=gutenberg.words(text1_id)\n",
    "text2_list=webtext.words(text2_id)\n",
    "print()\n",
    "\n",
    "#Tokenizing\n",
    "###########################################\n",
    "\n",
    "#Text lengths\n",
    "print('Text1 {} lenght: {} tokens'.format(text1_id, len(text1_list)))\n",
    "print('Text2 {} lenght: {} tokens'.format(text2_id, len(text2_list)))\n",
    "print()\n",
    "\n",
    "#Printing a part of sample texts\n",
    "print('Text1_list : ',text1_list[0:10])\n",
    "print('Text2_list : ',text2_list[0:10])\n",
    "print()\n",
    "\n",
    "#Accesing\n",
    "print('Index of the token \"flower\": ', text1_list.index('flower'))\n",
    "print('Token number 110552: ', text1_list[110552])\n",
    "print()\n",
    "\n",
    "#Joining text lists\n",
    "text1_string=\" \".join(text1_list)\n",
    "text2_string=\" \".join(text2_list)\n",
    "print('First 100 characters of joined text1_string: \\n',text1_string[0:100])\n",
    "print('First 100 characters of joined text2_string: \\n',text2_string[0:100])\n",
    "print()\n",
    "\n",
    "#Resplitting\n",
    "text1_string_resplit=text1_string.split()\n",
    "text2_string_resplit=text2_string.split()\n",
    "print('Text1_string_resplit : ',text1_string_resplit[0:10])\n",
    "print('Text2_string_resplit : ',text2_string_resplit[0:10])\n",
    "print('Text2_string_resplit : ',text2_string_resplit[0:10])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 concordance of the word \"precisely\":\n",
      "Displaying 7 of 7 matches:\n",
      "osity . The yeomanry are precisely the order of people with\n",
      "old you yesterday he was precisely the height of Mr . Perry\n",
      "mbled there , consisting precisely of those whose society w\n",
      "r stay at home .\" It was precisely what Emma would have wis\n",
      "s time with us . This is precisely what I wanted . Well , p\n",
      "rank the whole spring -- precisely the season of the year w\n",
      "an , and his manners are precisely what I like and approve \n",
      "\n",
      "\"precisely\" similar contexs:\n",
      "just to in at exactly perhaps by for more now however so that not all\n",
      "on this over gone always\n",
      "\n",
      "\"head\" and \"hart\" common contexs (tokens in left and rightside):\n",
      "his_at his_and her_was my_and my_i own_and\n"
     ]
    }
   ],
   "source": [
    "#Text object\n",
    "###########################################\n",
    "\n",
    "#Crating an instance of the NLTK text object\n",
    "#text list\n",
    "raw_text_sample=text1_string_resplit\n",
    "#nltk object\n",
    "text_object=Text(raw_text_sample)\n",
    "\n",
    "#Concordance\n",
    "###########################################\n",
    "\n",
    "#7 concordances of the word \"precisely\":\n",
    "print('7 concordance of the word \"precisely\":')\n",
    "text_object.concordance(word='precisely',width=60, lines=7)\n",
    "\n",
    "#Similarity - find words that are in common context\n",
    "###########################################\n",
    "print()\n",
    "print('\"precisely\" similar contexs:')\n",
    "text_object.similar('precisely')\n",
    "\n",
    "#Common context\n",
    "###########################################\n",
    "print()\n",
    "print('\"head\" and \"hart\" common contexs (tokens in left and rightside):')\n",
    "text_object.common_contexts(['head','heart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters number in raw text austen-emma.txt:  887071\n",
      "Characters number in rejoined text string:  915041\n",
      "Tokens number in raw text austen-emma.txt:  192427\n",
      "Tokens number in this rejoined text:  192427\n",
      "Tokens number in text1 is:  192427\n",
      "Unique tokens number in text1 is:  19317\n",
      "Occurence number of the word \"heaven\" in text1 is:  40\n",
      "Type of the variable \"fd\" : <class 'nltk.probability.FreqDist'>\n",
      "Frequency of the word \"you\" in text1 is: 841\n",
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a\n"
     ]
    }
   ],
   "source": [
    "#Counting\n",
    "###########################################\n",
    "\n",
    "#Note: For counting the characters you must use the \n",
    "######################\n",
    "######################\n",
    "print('Characters number in raw text {}: '.format(text1_id), len(gutenberg.raw(text1_id)))\n",
    "print('Characters number in rejoined text string: ', len(text1_string)) #reminder: text1_string=\" \".join(text1_list)\n",
    "\n",
    "\n",
    "print('Tokens number in raw text {}: '.format(text1_id), len(gutenberg.words(text1_id))) #reminder: text1_string=\" \".join(text1_list)\n",
    "print('Tokens number in this rejoined text: ', len(text1_string_resplit))\n",
    "\n",
    "\n",
    "print('Tokens number in text1 is: ',len(text1_list))  \n",
    "\n",
    "#notice that set return a list of unique tokens\n",
    "print('Unique tokens number in text1 is: ',len(set(text1))) #notice that set return a list of unique tokens\n",
    "print('Occurence number of the word \"heaven\" in text1 is: ',text1.count('heaven'))\n",
    "\n",
    "num_chars = len(gutenberg.raw('austen-emma.txt'))\n",
    "num_words = len(gutenberg.words('austen-emma.txt'))\n",
    "num_sents = len(gutenberg.sents('austen-emma.txt'))\n",
    "\n",
    "\n",
    "fd = nltk.FreqDist(text1) # creates a new data object that contains information about word frequency\n",
    "print('Type of the variable \"fd\" :', type(fd))\n",
    "print('Frequency of the word \"you\" in text1 is:', fd['you'])\n",
    "#fd.keys(), fd.values(), fd.items()\n",
    "print(gutenberg.raw(text1_id)[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
