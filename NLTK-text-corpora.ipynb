{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ids of the gutenberg corpus:\n",
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
      "\n",
      "File ids of the webtext corpus:\n",
      "['firefox.txt', 'grail.txt', 'overheard.txt', 'pirates.txt', 'singles.txt', 'wine.txt']\n",
      "\n",
      "Text1 id is:  austen-emma.txt\n",
      "Text2 id is:  grail.txt\n",
      "\n",
      "Text1 austen-emma.txt lenght: 192427 tokens\n",
      "Text2 grail.txt lenght: 16967 tokens\n",
      "\n",
      "Text1_list :  ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']\n",
      "Text2_list :  ['SCENE', '1', ':', '[', 'wind', ']', '[', 'clop', 'clop', 'clop']\n",
      "\n",
      "Index of the token \"flower\" in text1_list:  110552\n",
      "Token number 110552 in text1_list:  flower\n",
      "\n",
      "Text1_raw, first 100 characters of joined :\n",
      " She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence o\n",
      "Text1_string, first 100 characters of joined :\n",
      " her . She was the youngest of the two daughters of a most affectionate , indulgent father ; and had , in cons\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# An example of commonly used NLTK functions.\n",
    "# More info at http://www.nltk.org/py-modindex.html\n",
    "\n",
    "import nltk\n",
    "# Uncomment the download dialouge in case you don't have the corpora\n",
    "#nltk.download()\n",
    "\n",
    "from nltk.book import * #This says \"from NLTK's book module, load all items.\"\n",
    "# It is just a small module for educational purpose in chapter 1 of the NLTK tutorial\n",
    "# In this code we teplicate the classes that has been used in nltk.book module\n",
    "from nltk.corpus import gutenberg, webtext\n",
    "from __future__ import print_function\n",
    "\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import bigrams\n",
    "\n",
    "\n",
    "#Loading\n",
    "###########################################\n",
    "\n",
    "\n",
    "#Note: This first part is mostly useful to work with the nltk buit-in corpora.\n",
    "# E.g. num_sents = len(gutenberg.sents('austen-emma.txt'))\n",
    "\n",
    "# To use the external text corpora see the cell \"text object and external text\"\n",
    "######################\n",
    "######################\n",
    "gutenberg_fileids = gutenberg.fileids()\n",
    "webtext_fileids = webtext.fileids()\n",
    "\n",
    "print('File ids of the gutenberg corpus:\\n{}\\n'.format(gutenberg.fileids()))\n",
    "print('File ids of the webtext corpus:\\n{}\\n'.format(webtext.fileids()))\n",
    "\n",
    "#Selecting two sample text\n",
    "text1_id = gutenberg.fileids()[0]\n",
    "text2_id= webtext.fileids()[1]\n",
    "print('Text1 id is: ',text1_id)\n",
    "print('Text2 id is: ',text2_id)\n",
    "text1_list=gutenberg.words(text1_id)\n",
    "text2_list=webtext.words(text2_id)\n",
    "print()\n",
    "\n",
    "#Tokenizing\n",
    "###########################################\n",
    "\n",
    "#Text lengths\n",
    "print('Text1 {} lenght: {} tokens'.format(text1_id, len(text1_list)))\n",
    "print('Text2 {} lenght: {} tokens'.format(text2_id, len(text2_list)))\n",
    "print()\n",
    "\n",
    "#Printing a part of sample texts\n",
    "print('Text1_list : ',text1_list[0:10])\n",
    "print('Text2_list : ',text2_list[0:10])\n",
    "print()\n",
    "\n",
    "#Accesing\n",
    "print('Index of the token \"flower\" in text1_list: ', text1_list.index('flower'))\n",
    "print('Token number 110552 in text1_list: ', text1_list[110552])\n",
    "print()\n",
    "\n",
    "#Using nltk raw string\n",
    "text1_raw=gutenberg.raw(text1_id)\n",
    "text1_string=\" \".join(text1_list)\n",
    "print('Text1_raw, first 100 characters of joined :\\n',text1_raw[291:400])\n",
    "print('Text1_string, first 100 characters of joined :\\n',text1_string[291:400])\n",
    "print()\n",
    "\n",
    "#Resplitting\n",
    "text1_string_resplit=text1_string.split()\n",
    "#print('Text1_list : ',text1_list[50:60])\n",
    "#print('Text1_string_resplit : ',text1_string_resplit[50:60])\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters number in raw text austen-emma.txt:  887071\n",
      "Characters number in rejoined text string:  915041\n",
      "\n",
      "Tokens number in raw text austen-emma.txt:  192427\n",
      "\n",
      "Tokens number in raw text austen-emma.txt:  7752\n",
      "Tokens number in this rejoined text:  192427\n",
      "Unique tokens number in text1 is:  7811\n",
      "Occurence number of the word \"good\" in text1 is:  340\n",
      "\n",
      "Type of the variable \"fd\" : <class 'nltk.probability.FreqDist'>\n",
      "Frequency of the word \"good\" in text1 is: 340\n",
      "Frequency of the word \"good\" in text1 is: 192427\n"
     ]
    }
   ],
   "source": [
    "#Counting\n",
    "###########################################\n",
    "\n",
    "#Note: For counting the characters you must use e.g. raw text. If your text string is made by the join() method \n",
    "#      from a list, your text will have extra whitespace. e.g.   I asked her: \"how are you?\"\n",
    "#                                                         vs     I asked her : \" how are you ? \"\n",
    "######################\n",
    "######################\n",
    "print('Characters number in raw text {}: '.format(text1_id), len(gutenberg.raw(text1_id)))\n",
    "print('Characters number in rejoined text string: ', len(text1_string)) #reminder: text1_string=\" \".join(text1_list)\n",
    "print()\n",
    "\n",
    "print('Tokens number in raw text {}: '.format(text1_id), len(gutenberg.words(text1_id))) \n",
    "print()\n",
    "\n",
    "print('Tokens number in raw text {}: '.format(text1_id), len(gutenberg.sents(text1_id))) \n",
    "print('Tokens number in this rejoined text: ', len(text1_string_resplit))\n",
    "\n",
    "#notice that set return a list of unique tokens\n",
    "print('Unique tokens number in text1 is: ',len(set(text1_list))) #notice that set return a list of unique tokens\n",
    "print('Occurence number of the word \"good\" in text1 is: ',text1_list.count('good'))\n",
    "print()\n",
    "\n",
    "num_chars = len(gutenberg.raw('austen-emma.txt'))\n",
    "num_words = len(gutenberg.words('austen-emma.txt'))\n",
    "num_sents = len(gutenberg.sents('austen-emma.txt'))\n",
    "\n",
    "\n",
    "fd = nltk.FreqDist(text1_list) # creates a new data object that contains information about word frequency\n",
    "print('Type of the variable \"fd\" :', type(fd))\n",
    "print('Frequency of the word \"good\" in text1 is:', fd['good'])\n",
    "#fd.keys(), fd.values(), fd.items()\n",
    "#print(gutenberg.raw(text1_id)[0:100])\n",
    "\n",
    "print('Frequency of the word \"good\" in text1 is:', fd.N())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 concordance of the word \"precisely\":\n",
      "Displaying 7 of 7 matches:\n",
      "osity . The yeomanry are precisely the order of people with\n",
      "old you yesterday he was precisely the height of Mr . Perry\n",
      "mbled there , consisting precisely of those whose society w\n",
      "r stay at home .\" It was precisely what Emma would have wis\n",
      "s time with us . This is precisely what I wanted . Well , p\n",
      "rank the whole spring -- precisely the season of the year w\n",
      "an , and his manners are precisely what I like and approve \n",
      "\n",
      "\"precisely\" similar contexs:\n",
      "just to in at exactly perhaps by for more now however so that not all\n",
      "on this over gone always\n",
      "\n",
      "\"head\" and \"hart\" common contexs (tokens in left and rightside):\n",
      "his_at his_and her_was my_and my_i own_and\n"
     ]
    }
   ],
   "source": [
    "#Text objects / working with out of corpora texts\n",
    "###########################################\n",
    "\n",
    "#Crating an instance of the NLTK text object\n",
    "#text list\n",
    "raw_text_sample=text1_string_resplit\n",
    "#nltk object\n",
    "text_object=Text(raw_text_sample)\n",
    "\n",
    "#Concordance\n",
    "###########################################\n",
    "\n",
    "#7 concordances of the word \"precisely\":\n",
    "print('7 concordance of the word \"precisely\":')\n",
    "text_object.concordance(word='precisely',width=60, lines=7)\n",
    "\n",
    "#Similarity - find words that are in common context\n",
    "###########################################\n",
    "print()\n",
    "print('\"precisely\" similar contexs:')\n",
    "text_object.similar('precisely')\n",
    "\n",
    "#Common context\n",
    "###########################################\n",
    "print()\n",
    "print('\"head\" and \"hart\" common contexs (tokens in left and rightside):')\n",
    "text_object.common_contexts(['head','heart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
